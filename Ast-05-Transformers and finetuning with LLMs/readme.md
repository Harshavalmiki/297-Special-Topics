# CMPE-297-Transformers-and-finetuning-with-LLMs

**Question 2: 
Transformers and finetuning with LLMs**

**a) Implement nanogpt from scratch using your own code in pytorch, tensorflow and jax**

Text generation with NanoGPT using **Pytorch:**

**Colab link:** https://colab.research.google.com/drive/1vtZlUFy6PNprVCA6CkR-y-ZKFyDVTPIl?usp=sharing
Text generation with NanoGPT using **TensorFlow:**

**Colab link:** https://colab.research.google.com/drive/1rVJ2jyBj_oSJeA88pwNISew6Py1eEDPR?usp=sharing

Text generation with NanoGPT using **JAX:**

**Colab link:** https://colab.research.google.com/drive/17uKd-67fkaVXa4VBNJdVlYl_3O-tDqc4?usp=sharing


**b) Implement "textbooks are all you need"**

Used the existing model that is finetuned with python dataset to finetune the model. 

**Colab link:** https://colab.research.google.com/drive/1BHFjMLTJ7_-kBQsKtMhEblEA_cWW-Q09?usp=sharing